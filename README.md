# AI-chatbot completion api

## DescriÃ§Ã£o

O projeto consiste em uma API que utiliza o OpenAI ChatGPT para responder a perguntas com base em um conjunto limitado de dados sem a necessidade de treinamento do modelo, usando a tÃ©cnica de [Retrieval-Augmented Generation (RAG)](https://lucvandonkersgoed.com/2023/12/11/retrieval-augmented-generation-rag-simply-explained/).

## Setup do projeto

ğŸŸ© Node.js v22.17.1

Como rodar o projeto sem docker

```bash
    cp sample_.env .env   #preencha as variÃ¡veis de ambiente
    npm install
    npm run dev
```

Como rodar os testes (Opcional)

```bash
    npm run test
```

Como rodar o projeto com docker

```bash
    docker-compose up -d
```

DocumentaÃ§Ã£o OpenAPI (Swagger)

```bash
    acesse a rota /api
```

## Estrutura do projeto

```bash
project-root/
â”œâ”€â”€ src/                    # CÃ³digo-fonte principal da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ modules/            # MÃ³dulos organizados por domÃ­nio/funcionalidade
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ controller/     # Camada responsÃ¡vel por receber requisiÃ§Ãµes e chamar os serviÃ§os
â”‚   â”‚   â”œâ”€â”€ dto/            # Data Transfer Objects: definem a forma dos dados esperados nas requisiÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ interface/      # DefiniÃ§Ãµes de interfaces e tipos compartilhados
â”‚   â”‚   â”œâ”€â”€ repository/     # ComunicaÃ§Ã£o com o banco de dados ou outras fontes de dados
â”‚   â”‚   â”œâ”€â”€ service/        # Regras de negÃ³cio e lÃ³gica da aplicaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ test/
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ mocks/      # Arquivos de simulaÃ§Ã£o input/output para testes
â”‚   â”‚
â”‚   â”œâ”€â”€ swagger/            # ConfiguraÃ§Ãµes e definiÃ§Ãµes do Swagger (OpenAPI) para documentaÃ§Ã£o da API
â”‚   â”‚
â”‚   â”œâ”€â”€ main.ts             # Ponto de entrada da aplicaÃ§Ã£o (bootstrap)
â”‚
â”œâ”€â”€ .env                    # VariÃ¡veis de ambiente (ex: credenciais, URLs, etc.)
â”œâ”€â”€ .nvmrc                  # Define a versÃ£o do Node.js usada no projeto
â”œâ”€â”€ Dockerfile              # Arquivo de configuraÃ§Ã£o do Docker para construir a imagem do container
```

## Principais decisÃµes tÃ©cnicas

### DependÃªncias e Tecnologias

Nestjs: framework backend modular e baseado em injeÃ§Ã£o de dependÃªncia.
OpenAI SDK: geraÃ§Ã£o de embeddings e respostas via API oficial.
Typescript: para tipagem e consistÃªncia de contrato.

### SeparaÃ§Ã£o de responsabilidades (Single Responsibility Principle):

O serviÃ§o ConversationsService tem como objetivo orquestrar a geraÃ§Ã£o de respostas do agente de IA. Ele nÃ£o se preocupa com a implementaÃ§Ã£o da IA ou armazenamento de embeddings diretamente â€” isso Ã© delegado a serviÃ§os especializados:

OpenaiApiService: encapsula chamadas ao OpenAI para gerar embeddings e respostas.

ClaudIaService: responsÃ¡vel por buscas os vetores baseados no embeddings da pergunta do usuÃ¡rio.

### Uso de Embeddings para busca contextual

Antes de gerar qualquer resposta, o serviÃ§o extrai a Ãºltima mensagem do usuÃ¡rio, gera um embedding e realiza a busca vetorial baseado no embedding da mensagem do usuÃ¡rio. O contÃ©udo recuperado Ã© entÃ£o utilizado como contexto adicional no prompot do agente.

### Design imutÃ¡vel de Mensagens

A manipulaÃ§Ã£o das mensagens do usuÃ¡rio e da IA Ã© imutÃ¡vel e explÃ­cita, a resposta da IA nunca substitui a anterior e o histÃ³rico Ã© tambÃ©m passado como contexto para a prÃ³xima interaÃ§Ã£o.

No momento a api nÃ£o persiste nenhuma mensagem em nenhum tipo de banco de dados, mas o histÃ³rico Ã© armazenado no contexto da resposta.

E se o histÃ³rico de mensagens recebido pela api for muito grande, nÃ£o Ã© garantia que a resposta da IA vai considerar todas as informaÃ§Ãµes, visto que pode transbordar a janela de contexto (tokens) do prompt.

### Uso de Prompt Engineer para Controle Rigoroso de Respostas

A systemPrompt Ã© definida como uma constante controladora, com instruÃ§Ãµes explÃ­citas:

A IA nunca deve inventar respostas (respeita o [princÃ­pio de groundedness](https://www.conversion.com.br/blog/o-que-e-grounding/)).

A IA julga se consegue da uma resposta de qualidade baseado no contexto fornecido ou no histÃ³rico da conversa.

```bash
Exemplo de resposta considerando informaÃ§Ãµes do histÃ³rico da conversa:
```

```json
{
  "messages": [
    {
      "role": "USER",
      "content": "Hello! How long does a Tesla battery last before it needs to be replaced?"
    },
    {
      "role": "AGENT",
      "content": "Hello! How can I assist you today? I'm Claudia, your Tesla support assistant ğŸ˜Š\nTesla batteries are designed to last many years; the vehicle will notify you if maintenance is needed! Let me know if you have more questions! ğŸš—âš¡"
    },
    {
      "role": "USER",
      "content": "My name is Mike"
    },
    {
      "role": "USER",
      "content": "Do you know my name? if yes, tell me"
    },
    {
      "role": "AGENT",
      "content": "Yes, you mentioned your name is Mike ğŸ˜ŠğŸš—. How can I assist you further today, Mike?"
    }
  ],
  "handoverToHumanNeeded": true,
  "sectionsRetrieved": [
    {
      "score": 0.38024405,
      "content": "Can I buy a Tesla with cryptos like DogeCoins? Yes, this is possible, I'll forward you to talk with Elon. Wait a second please."
    },
    {
      "score": 0.36369288,
      "content": "Can I control my Tesla with my phone? Yes, the Tesla app allows you to lock/unlock doors, check the battery charge, and activate climate control."
    },
    {
      "score": 0.35677007,
      "content": "Does Tesla offer customer support? Yes, Tesla provides support via phone, email, and directly through the app."
    }
  ]
}
```

Quando nÃ£o hÃ¡ contexto suficiente, a IA responde com uma mensagem padrÃ£o (noAnswerMessage). TambÃ©m seria possÃ­vel definir uma mensagem mais dinÃ¢mica com apenas um pequeno trecho padrÃ£o.

Emojis sÃ£o utilizados para manter um tom leve e amigÃ¡vel. ğŸ˜„

### Redirecionamento para humano quando ausÃªncia de contexto

A IA tem duas chances de pedir por detalhes adicionais antes de redirecionar a conversa para um humano, caso ela mesma julgue que a pergunta do usuÃ¡rio nÃ£o tem relaÃ§Ã£o com o contexto fornecido.

```bash
Exemplo de resposta quando a IA julga que a pergunta do usuÃ¡rio nÃ£o tem relaÃ§Ã£o com o contexto fornecido:

```

```json
{
  "messages": [
    {
      "role": "USER",
      "content": "How can IA make a hamburguer?"
    },
    {
      "role": "AGENT",
      "content": "Sorry, but I didn't fully understand your question. Could you please provide more details or rephrase the question so I can better assist you?"
    },
    {
      "role": "USER",
      "content": "Come on, I know you know"
    },
    {
      "role": "AGENT",
      "content": "\"Sorry, but I couldn't understand your question again ğŸ˜•. To make sure you get the best help, I'll redirect our conversation to one of our human specialists ğŸ§‘â€ğŸ’¼âœ¨\""
    }
  ],
  "handoverToHumanNeeded": true,
  "sectionsRetrieved": [
    {
      "score": 0.36641753,
      "content": "Can I buy a Tesla with cryptos like DogeCoins? Yes, this is possible, I'll forward you to talk with Elon. Wait a second please."
    },
    {
      "score": 0.3554426,
      "content": "Do I have to pay to use Superchargers? Yes, there is usually a fee, although some older models come with free charging."
    },
    {
      "score": 0.35262728,
      "content": "Where can I find a Supercharger station? You can locate Supercharger stations on the Tesla website and in the carâ€™s navigation system."
    }
  ]
}
```

### Redirecionamento automÃ¡tico para humano quando contexto recebido pela IA tem type N2.

ConteÃºdo com type N1: IA tem a capacidade de responder sozinha.

ConteÃºdo com type N2: IA nÃ£o tem a capacidade de responder sozinha.

Quando o sistema identifica que pelo menos um dos conteÃºdo retornado pelo Vetor tem o tipo N2, ele redireciona a conversa para um humano "setando" a propriedade handoverToHumanNeeded: true.
